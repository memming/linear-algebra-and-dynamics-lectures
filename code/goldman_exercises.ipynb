{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507d96b-a2ec-4e2d-9eb7-1fb0cdc608ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "currentdir = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(\"notebook\", font_scale=1.25, rc={\"lines.linewidth\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54bc70-1a68-4e2e-ba82-35649782b97f",
   "metadata": {},
   "source": [
    "Based on \n",
    "- Goldman, Mark S. \"Memory without feedback in a neural network.\" Neuron 61.4 (2009): 621-634.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd256393-69cd-459f-bd38-2c3e5e59fb6b",
   "metadata": {},
   "source": [
    "## Integration by a Feedforward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db7377d-7034-422b-ac6c-cdf39fe1dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eigenvalues(eigvals):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.scatter(np.real(eigvals), np.imag(eigvals))\n",
    "    plt.xlim([-1.1,1.1])\n",
    "    plt.ylim([-1.1,1.1])\n",
    "    plt.xlabel(r\"Re($\\lambda$)\")\n",
    "    plt.ylabel(r\"Im($\\lambda$)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e1a01-3fd3-4de0-b2d0-fdaab0a27db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = .1 #time scale for neurons\n",
    "dt = .01 #integration constant (\\Delta)\n",
    "\n",
    "def simulate_network(W, maxT, a_weights, x, dt=dt, tau=tau):\n",
    "    \"\"\"Simulates the activity of a network with connectivity matrix W for times T.\"\"\"\n",
    "    N = W.shape[0]\n",
    "    r = np.zeros(N) #initial state\n",
    "    all_r = np.zeros((maxT,N))\n",
    "    for t in range(maxT):\n",
    "        r += ((-r + r @ W)*dt)/tau + np.multiply(a_weights, x[t])\n",
    "        all_r[t,:] = r\n",
    "    return all_r\n",
    "\n",
    "\n",
    "maxT = int(10/dt) #maximum time for simulation\n",
    "times = np.arange(maxT)*dt #time vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe1dc3b-2018-4ed7-a7bc-fb40dd6e11d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100 #number of neurons\n",
    "\n",
    "#input: a_i represents the strength of the external input to unit i\n",
    "a_weights = np.zeros(N)\n",
    "a_weights[0] = 1.\n",
    "\n",
    "#input x(t)\n",
    "x = np.zeros(maxT)\n",
    "x[0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e98e4-b4ef-41bb-a74d-c27f742d3c1c",
   "metadata": {},
   "source": [
    "##### Excercise 1: Plot the input x(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd358be-84bd-4703-892c-791d745dfe87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acc6bebd-95f6-4ad0-a63d-8e067ebc33c5",
   "metadata": {},
   "source": [
    "##### Excercise 2: Construct the feedforward network\n",
    "This network corresponds to a feedforward chain of neurons with $W_{ij}$ = 1 if $i=j+1$ and 0 otherwise. \n",
    "$$W = \n",
    "\\begin{bmatrix}\n",
    "0 & 1 & 0 & \\dots & 0\\\\\n",
    "0 & 0 & 1 & \\dots & 0\\\\\n",
    "\\vdots &&& \\ddots & \\vdots  \\\\\n",
    "0 & 0 & 0 & \\dots & 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b4888-802d-459d-9476-72c5adf54585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f493f8-5343-46fb-aefd-87aec9f178d0",
   "metadata": {},
   "source": [
    "#### Integration of a pulse into a step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15d14b-4970-4fe1-85f2-5a20b6c9b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 1 #input\n",
    "all_r = simulate_network(W, maxT, a_weights, I*x)\n",
    "output_weights =  np.ones(N)\n",
    "weighted_sum = np.dot(all_r, output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8237e17f-6c58-48e3-b8fd-916358117550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 1B\n",
    "#maintained memory of pulse\n",
    "fig, axs = plt.subplots(2, 1, figsize=(7, 7), sharex=True)\n",
    "idx = [i for i in range(0, 100, 7)] #select each 7th neuron's activity\n",
    "axs[0].plot(times, all_r[:,idx])\n",
    "    \n",
    "axs[1].plot(times, weighted_sum)\n",
    "axs[1].set_ylim([0,I*1.03])\n",
    "plt.xlabel(\"Time (sec)\");\n",
    "plt.ylabel(\"Output $r_{out}$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f08a1f-f4f2-49b3-8094-67378f306d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure 1E: Integration\n",
    "# step input leads to a linear ramping output with slope proportional to the size of the step\n",
    "I = .005\n",
    "x = np.ones(maxT) #step input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811d6b72-3c7c-4fbe-8c77-f2dcf5a57c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_r = simulate_network(W, maxT, a_weights, I*x)\n",
    "output_weights =  np.ones(N)\n",
    "weighted_sum = np.dot(all_r, output_weights)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 4), sharex=True)\n",
    "\n",
    "ax.plot(times, weighted_sum)\n",
    "ax.set_ylim([0,10*1.03])\n",
    "plt.xlabel(\"Time (sec)\");\n",
    "plt.ylabel(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d0f6cc-cb26-4a7b-ac8d-8d95d3b61f49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83cabf83-c4a8-4bd7-8447-4976bbeaad8e",
   "metadata": {},
   "source": [
    "### Feedforward Processing of Inputs by a Recurrent Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68243fd3-06ef-44dd-93d7-e7b94c20c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feedforward function of feedforward and recurrent networks\n",
    "#random orthogonal network \n",
    "N=3\n",
    "random_vecs = np.random.randn(N, N)\n",
    "U, R = np.linalg.qr(random_vecs)\n",
    "\n",
    "#feedforward connectivity \n",
    "T_matrix = np.diag(np.ones((1, N-1))[0], 1)\n",
    "W = U @ T_matrix @ np.linalg.inv(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b602252b-6b76-4ab4-b54e-f16e5155d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxT = int(1/dt)\n",
    "times = np.arange(maxT)*tau\n",
    "x = np.zeros(maxT)\n",
    "x[0] = 1\n",
    "a_weights = np.zeros(N)\n",
    "a_weights[0] = 1.\n",
    "all_r_ff = simulate_network(T_matrix, maxT, a_weights, x) \n",
    "\n",
    "#for the input to be propagated throught the network equivalently to a neuron's activity, we need to project it onto the correct pattern:\n",
    "a_weights = U @ a_weights \n",
    "all_r_rec = simulate_network(W, maxT, a_weights, x).T\n",
    "\n",
    "fig, axs = plt.subplots(2,1,  figsize=(7, 7), sharex=True)\n",
    "colors = ['red', 'blue', 'blueviolet']\n",
    "for i in range(N):\n",
    "    axs[0].plot(times, all_r_ff[:,i], c=colors[i], label=i)\n",
    "    axs[1].plot(times, all_r_rec.T[:,i], c=colors[i], label=i)\n",
    "axs[0].set_title(\"Feedforward architecture\")\n",
    "axs[1].set_title(\"Recurrent architecture\")\n",
    "plt.xlabel(r\"Time (in units of $\\tau$)\");\n",
    "axs[0].legend();\n",
    "axs[1].legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace44612-e6ae-4306-8701-abd23b89f24f",
   "metadata": {},
   "source": [
    "##### Exercise 3.1: Plot the activity in the rotated neural space (see also Question 32. from the Syllabus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f5de8c-f79d-4bde-ba91-5e0ba0c2bfef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22767123-d943-4f38-9218-5defd5eea64d",
   "metadata": {},
   "source": [
    "##### Exercise 3.2 What are the patterns of activity that behave as neurons equivalent to neurons in the feedforward network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eee866f-7135-4e1c-8e25-fa2fcf33e9e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07adaa19-d4ec-438f-bfa6-827ab9a23002",
   "metadata": {},
   "source": [
    "### Schur, but Not Eigenvector, Decomposition Reveals Feedforward Interactions between Patterns of Activity\n",
    "We will investigate three different networks, a pure feedback network, a functionally feedforward and a functionally mixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e182e3-d113-40a5-9c4e-c95757cf7814",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2\n",
    "W_pure = np.ones((N,N))/2. #pure feedback\n",
    "\n",
    "W_fff = np.array([[1,-1],[1,-1]])/2. #functionally feedforward\n",
    "\n",
    "W_mixed = np.array([[1/2.,-0.3],[1/2.,-0.3]])\n",
    "\n",
    "weight_list = [W_pure, W_fff, W_mixed]\n",
    "label_list = [\"Pure\\nfeedback\", \"Functionally\\nfeedforward\", \"Functionally mixed\"]\n",
    "\n",
    "a_weights = np.zeros(N)\n",
    "a_weights[0] = 1.\n",
    "\n",
    "output_weights =  np.ones(N)\n",
    "\n",
    "maxT = int(.5/dt)\n",
    "times = np.arange(maxT)*tau\n",
    "I = 2\n",
    "x = np.zeros(maxT)\n",
    "x[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d138dfa1-b658-4a18-b394-f2f98c93e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12, 2), sharey=True)\n",
    "for i, W in enumerate(weight_list):\n",
    "    all_r = simulate_network(W, maxT, a_weights, I*x)\n",
    "    \n",
    "    axs[i].plot(times, all_r[:,0], '-g', times, np.abs(all_r[:,1]), '-c')\n",
    "    axs[i].set_xlabel(r\"Time (in units of $\\tau$)\")\n",
    "    axs[i].set_title(label_list[i])\n",
    "exp_dec = np.exp(-times)\n",
    "axs[1].plot(times, exp_dec, '--k')\n",
    "axs[0].set_ylabel(\"Neural \\n response\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c082cbf-14cf-4ccd-84f3-925a1f10e175",
   "metadata": {},
   "source": [
    "##### Exercise 4: Read off the eigenvalues of the connectivity matrix from the activity plots for the pure feedback network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c3732d-89b8-4e68-b91d-81fee670c69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8fed08a-64d2-48d9-a5e6-2f2b90d75e87",
   "metadata": {},
   "source": [
    "##### Exercise 5: Given the eigenvectors, simulate the activity in the eigenmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ca9ec-6cd1-4541-bea0-ec71ce523edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eigenvectors:\n",
    "V_pure = np.array([[1,1],[1,-1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54d3063-d695-4da4-aa8b-57028b9bc08d",
   "metadata": {},
   "source": [
    "##### Exercise 6: Given the eigenvectors for the feedforward network, what are the eigenvalues?\n",
    "- Why can the matrix not be eigendecomposed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25cfcd-5722-4d93-b2b3-5e122f290518",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_feedforward = np.array([[1,1],[1,1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aac31b-aaa5-4939-a855-b4aad7858fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53773c7-d4a2-4322-8ae7-6dd438355088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3266600d-f829-4b4f-a5b5-77b042416c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#degenerate eigenvectors: inverse V does not exist\n",
    "#nonorthogonal eigenvectors: eigenmodes are very different from the Cartesian axes x_1 and x_2 that define the firing activity of the individual neurons\n",
    "colormap = np.array(['blue', 'red'])\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(9, 6))\n",
    "for i, W in enumerate(weight_list):\n",
    "    eigvals, eigvecs = np.linalg.eig(W)\n",
    "    eigvecs /= np.max(eigvecs, axis=0)\n",
    "\n",
    "    if np.all(np.real(eigvecs[:,0]) != np.real(eigvecs[:,1])):\n",
    "        all_r = np.linalg.inv(eigvecs.T) @ simulate_network(W, maxT, a_weights, I*x).T \n",
    "\n",
    "        axs[0][i].plot(times, all_r[0,:], '-r', times, all_r[1,:], '-b')\n",
    "        axs[0][i].set_xlabel(r\"Time (in units of $\\tau$)\")\n",
    "        axs[0][i].set_title(label_list[i])\n",
    "    else:\n",
    "        0\n",
    "        \n",
    "    for j, (eigval, eigvec) in enumerate(zip(eigvals, eigvecs.T)):\n",
    "        eignorm = np.linalg.norm(eigval)\n",
    "        im = axs[1][i].scatter(np.sign(eigvec[0])*eigvec[0], np.sign(eigvec[0])*eigvec[1], c=colormap[j])  #np.where(np.around(eignorm, 10)>0,0,1)\n",
    "        \n",
    "    axs[1][i].axhline(0, linestyle='--', color='grey')\n",
    "    axs[1][i].axvline(0, linestyle='--', color='grey')\n",
    "    axs[1][i].set_xlim([-1.1,1.1])\n",
    "    axs[1][i].set_ylim([-1.1,1.1])\n",
    "    axs[1][i].set_xlabel(r\"$x_1$\")\n",
    "    \n",
    "axs[1][0].set_ylabel(r\"$x_2$\")\n",
    "all_r = simulate_network(W, maxT, a_weights, x)\n",
    "plt.tight_layout();\n",
    "axs[0][0].set_ylabel(\"Neural \\n response\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49acf923-1001-47e6-acf6-3c75d04d1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Exercise 7: How can you see in these plots that the eigenvector represents feedback only onto themselves?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18617e86-bdee-45b0-8678-690587479d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4d9eec1-41b6-488d-9c00-fd59ad2cfcb5",
   "metadata": {},
   "source": [
    "### The Schur Decompositions\n",
    "The Schur decomposition always produces orthogonal eigenmodes.\n",
    "\n",
    "This means that the Schur, but not the eigenvector, modes behave analogously to interconnected neurons\n",
    "\n",
    "The Schur decomposition can be computed with scipy's linalg.schur:\n",
    "\n",
    "T, U = scipy.linalg.schur(W)\n",
    "\n",
    "Which gives us the decomposition $$W = U T U^{-1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2aa374-46dd-4b3b-b880-61aa59df198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(6, 2), sharey=True)\n",
    "for i, W in enumerate(weight_list):\n",
    "    T_mat, U = scipy.linalg.schur(W)\n",
    "    U /=  np.max(U, axis=1) # np.linalg.norm(U, axis=1)\n",
    "    U *= np.sign(U[1,:])\n",
    "    for j, (eigval, eigvec) in enumerate(zip(eigvals, U.T)):\n",
    "        eignorm = np.linalg.norm(eigval)\n",
    "        im = axs[i].scatter(eigvec[1], eigvec[0], c=colormap[j])  #np.where(np.around(eignorm, 10)>0,0,1)\n",
    "        \n",
    "    axs[i].axhline(0, linestyle='--', color='grey')\n",
    "    axs[i].axvline(0, linestyle='--', color='grey')\n",
    "    axs[i].set_xlim([-1.1,1.1])\n",
    "    axs[i].set_ylim([-1.1,1.1])\n",
    "\n",
    "    axs[i].set_xlabel(r\"$x_1$\")\n",
    "    axs[i].set_title(label_list[i])\n",
    "    \n",
    "axs[0].set_ylabel(r\"$x_2$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51c6e6-c728-4915-870d-d0263cfa2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12, 2))\n",
    "for i, W in enumerate(weight_list):\n",
    "    T_mat, U = scipy.linalg.schur(W)\n",
    "    U /= np.sqrt(2)\n",
    "    U *= np.sign(U[0,:])\n",
    "    all_r =  U.T @ simulate_network(W, maxT, a_weights, I*x).T\n",
    "    \n",
    "    axs[i].plot(times, all_r[0,:], '-r', times, all_r[1,:], '-b')\n",
    "    axs[i].set_xlabel(r\"Time (in units of $\\tau$)\")\n",
    "    axs[i].set_title(label_list[i])\n",
    "axs[0].set_ylabel(\"Neural \\n response\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5762a-4c3f-43be-81c4-f507ec0359e0",
   "metadata": {},
   "source": [
    "##### Exercise 8: How can you reconstruct the neural activity from the activities of the Schur modes?\n",
    "Hint: _Balanced Amplification: A New Mechanism of Selective Amplification of Neural Activity Patterns_\n",
    "Murphy, Brendan K., and Kenneth D. Miller. \"Balanced amplification: a new mechanism of selective amplification of neural activity patterns.\" Neuron 61.4 (2009): 635-648.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1ce901-28a7-4ecc-b58d-63050d454032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60202231-a576-4392-bd78-23c0fe4aca95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee69854-e154-4f11-bdad-704de4b70370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b05cc1-82cf-4f42-beb0-a25aa0e9c858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "358199bb-60d2-4afc-9f7d-84ee8cbe2b6d",
   "metadata": {},
   "source": [
    "#### Some additional networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c949c8-d376-4b57-8637-8e73ebb171bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transient amplification\n",
    "W_mixed = np.array([[1+1/2.,-1.8],[1+1/2.,-1.8]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff02427-4669-4cf7-83bd-06340cf7442a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cyclic network\n",
    "N = 10\n",
    "maxT = int(10/dt)\n",
    "times = np.arange(maxT)*dt\n",
    "\n",
    "W = np.diag(np.ones((1, N-1))[0], -1) #(feedfoward + one connection last to first unit)\n",
    "W[0,-1] = 1.\n",
    "\n",
    "a_weights = np.zeros(N)\n",
    "a_weights[0] = 1.\n",
    "\n",
    "I = 1\n",
    "x = np.zeros(maxT)\n",
    "x[0] = 1\n",
    "all_r = simulate_network(W, maxT, a_weights, I*x)\n",
    "output_weights =  np.ones(N)\n",
    "weighted_sum = np.dot(all_r, output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bf3bc3-9132-419a-8a9b-a2d789260cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure \n",
    "fig, axs = plt.subplots(2, 1, figsize=(7, 7), sharex=True)\n",
    "axs[0].plot(times, all_r)\n",
    "axs[1].plot(times, weighted_sum)\n",
    "axs[1].set_ylim([0,I*1.03])\n",
    "plt.xlabel(\"Time (sec)\");\n",
    "plt.ylabel(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dcda35-6aff-4ace-913a-e03a8a96c1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\", font_scale=1.)\n",
    "eigvals, eigvecs = np.linalg.eig(W)\n",
    "plot_eigenvalues(eigvals);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f62caa1-9c85-432c-8708-909e2c390c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3119a5-be73-4c6a-b02f-0b22b913bb60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c597728-d6b3-4aae-8819-14cf44a42182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#line attractor (low-rank network)\n",
    "N = 2\n",
    "a = np.random.randn(N)\n",
    "b = np.random.randn(N)\n",
    "a, b = (a,b)/np.sqrt(np.inner(a,b))\n",
    "W = np.outer(a, b)\n",
    "\n",
    "eigvals, eigvecs = np.linalg.eig(W)\n",
    "plot_eigenvalues(eigvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2047a-3053-4ddb-92d6-7cc0467979f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros(maxT)\n",
    "x[0] = 1\n",
    "a_weights = np.zeros(N)\n",
    "a_weights[0] = 1.\n",
    "\n",
    "all_r = simulate_network(W, maxT, a_weights, I*x)\n",
    "output_weights =  np.ones(N)\n",
    "weighted_sum = np.dot(all_r, output_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9985c70-8897-48b8-a1cb-c592f889b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure \n",
    "fig, axs = plt.subplots(2, 1, figsize=(7, 7), sharex=True)\n",
    "axs[0].plot(times, all_r)\n",
    "axs[1].plot(times, weighted_sum)\n",
    "axs[1].set_ylim([-1,1.03])\n",
    "plt.xlabel(\"Time (sec)\");\n",
    "plt.ylabel(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d9cf96-0636-46bb-91ce-a3697b8bfc77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
